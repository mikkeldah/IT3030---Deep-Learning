{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stacked_mnist import StackedMNISTData, DataMode\n",
    "from models.vae import VAE\n",
    "from models.mnist_classifier import MNISTClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the provided mnist dataset class\n",
    "gen = StackedMNISTData(mode=DataMode.COLOR_BINARY_COMPLETE, default_batch_size=9)\n",
    "\n",
    "train_data = gen.get_full_data_set(training=True)\n",
    "test_data = gen.get_full_data_set(training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 3), (10000, 28, 28, 3))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape, test_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 3) (60000,)\n",
      "(10000, 28, 28, 3) (10000,)\n",
      "(28, 28, 3)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5040b79310>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, y_train = train_data\n",
    "x_test, y_test = test_data\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "# Convert y_train and y_test into one-hot vectors\n",
    "y_train = to_one_hot_rgb(y_train)\n",
    "y_test = to_one_hot_rgb(y_test)\n",
    "\n",
    "rand = np.random.randint(0, x_train.shape[0])\n",
    "img = x_train[rand]\n",
    "label = y_train[rand]\n",
    "print(img.shape)\n",
    "\n",
    "print(label)\n",
    "print(label.argmax())\n",
    "plt.figure(figsize=(6, 4), dpi=150)\n",
    "plt.imshow(img*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pytorch dataloaders from x_train and y_train\n",
    "x_train = torch.from_numpy(x_train.astype(np.float32)).permute(0, 3, 1, 2)\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Create pytorch dataloaders from x_test and y_test\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32)).permute(0, 3, 1, 2)\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VAELoss(bce_loss, mu, logvar):\n",
    "    BCE = bce_loss \n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 41758.649690998136\n",
      "Test Loss: 37228.18310857882\n",
      "Epoch: 1, Loss: 36988.19646605144\n",
      "Test Loss: 36311.888553692275\n",
      "Epoch: 2, Loss: 36193.34136169043\n",
      "Test Loss: 35496.41706060908\n",
      "Epoch: 3, Loss: 35435.915478411516\n",
      "Test Loss: 34886.38801253981\n",
      "Epoch: 4, Loss: 35035.4836358109\n",
      "Test Loss: 34627.58602458201\n",
      "Epoch: 5, Loss: 34861.76078383195\n",
      "Test Loss: 34519.964147093946\n",
      "Epoch: 6, Loss: 34716.22249383662\n",
      "Test Loss: 34402.05367361664\n",
      "Epoch: 7, Loss: 34556.13572761194\n",
      "Test Loss: 34214.38405652866\n",
      "Epoch: 8, Loss: 34433.672682902456\n",
      "Test Loss: 34078.27963276274\n",
      "Epoch: 9, Loss: 33283.59567397388\n",
      "Test Loss: 31810.53445959395\n",
      "Epoch: 10, Loss: 31577.602732709223\n",
      "Test Loss: 30864.470510300558\n",
      "Epoch: 11, Loss: 30805.447284365004\n",
      "Test Loss: 30353.0095790207\n",
      "Epoch: 12, Loss: 30401.19782157849\n",
      "Test Loss: 29935.816207205415\n",
      "Epoch: 13, Loss: 30137.220456381598\n",
      "Test Loss: 29744.52521957106\n",
      "Epoch: 14, Loss: 29950.966388759327\n",
      "Test Loss: 29619.864307573647\n",
      "Epoch: 15, Loss: 29806.787356118402\n",
      "Test Loss: 29461.925392491044\n",
      "Epoch: 16, Loss: 29692.236855968484\n",
      "Test Loss: 29328.627344994027\n",
      "Epoch: 17, Loss: 29596.061282940766\n",
      "Test Loss: 29286.576420680733\n",
      "Epoch: 18, Loss: 29514.151267240806\n",
      "Test Loss: 29217.08122574144\n",
      "Epoch: 19, Loss: 29434.722621893325\n",
      "Test Loss: 29123.921452030256\n",
      "Epoch: 20, Loss: 29365.378964552237\n",
      "Test Loss: 29057.55637937898\n",
      "Epoch: 21, Loss: 29308.761039945362\n",
      "Test Loss: 29154.074119227706\n",
      "Epoch: 22, Loss: 29258.612050656317\n",
      "Test Loss: 28972.498839943273\n",
      "Epoch: 23, Loss: 29195.603902918443\n",
      "Test Loss: 28979.472516296777\n",
      "Epoch: 24, Loss: 29156.123921408584\n",
      "Test Loss: 28880.63912594546\n",
      "Epoch: 25, Loss: 29106.632373150987\n",
      "Test Loss: 28839.959932946855\n",
      "Epoch: 26, Loss: 29047.801837978077\n",
      "Test Loss: 28813.463739674564\n",
      "Epoch: 27, Loss: 28879.739069371335\n",
      "Test Loss: 28499.228857732884\n",
      "Epoch: 28, Loss: 28520.349157532648\n",
      "Test Loss: 28086.16111415207\n",
      "Epoch: 29, Loss: 28262.39448856443\n",
      "Test Loss: 28044.11283028961\n",
      "Epoch: 30, Loss: 28103.73717767191\n",
      "Test Loss: 27899.689027045184\n",
      "Epoch: 31, Loss: 27978.897428663047\n",
      "Test Loss: 27710.651081060907\n",
      "Epoch: 32, Loss: 27891.96121235341\n",
      "Test Loss: 27708.87370621019\n",
      "Epoch: 33, Loss: 27813.927376232677\n",
      "Test Loss: 27640.117529607884\n",
      "Epoch: 34, Loss: 27743.21528830457\n",
      "Test Loss: 27555.546364948248\n",
      "Epoch: 35, Loss: 27678.898628023388\n",
      "Test Loss: 27488.046128582802\n",
      "Epoch: 36, Loss: 27625.090873409183\n",
      "Test Loss: 27404.95280777269\n",
      "Epoch: 37, Loss: 27574.904632112874\n",
      "Test Loss: 27309.291531896895\n",
      "Epoch: 38, Loss: 27527.673454366006\n",
      "Test Loss: 27274.318234972136\n",
      "Epoch: 39, Loss: 27480.11672941098\n",
      "Test Loss: 27385.48167234773\n",
      "Epoch: 40, Loss: 27422.48515166911\n",
      "Test Loss: 27223.723303144903\n",
      "Epoch: 41, Loss: 27375.109910131265\n",
      "Test Loss: 27390.79693098129\n",
      "Epoch: 42, Loss: 27278.920338319564\n",
      "Test Loss: 26991.2712977707\n",
      "Epoch: 43, Loss: 27158.985105860207\n",
      "Test Loss: 26992.579540082603\n",
      "Epoch: 44, Loss: 27022.315919009863\n",
      "Test Loss: 26895.72222395004\n",
      "Epoch: 45, Loss: 26926.910916261328\n",
      "Test Loss: 26782.128377537818\n",
      "Epoch: 46, Loss: 26817.738521746734\n",
      "Test Loss: 26606.757594794984\n",
      "Epoch: 47, Loss: 26727.803521455226\n",
      "Test Loss: 26542.73676353503\n",
      "Epoch: 48, Loss: 26645.633756788047\n",
      "Test Loss: 26491.517229796973\n",
      "Epoch: 49, Loss: 26548.483394273055\n",
      "Test Loss: 26367.058830115446\n",
      "Epoch: 50, Loss: 26450.755639700492\n",
      "Test Loss: 26311.987410429938\n",
      "Epoch: 51, Loss: 26348.566571786712\n",
      "Test Loss: 26111.8687456459\n",
      "Epoch: 52, Loss: 26251.151150636328\n",
      "Test Loss: 26124.816418690287\n",
      "Epoch: 53, Loss: 26153.788223364205\n",
      "Test Loss: 25983.879571805333\n",
      "Epoch: 54, Loss: 26056.99523379198\n",
      "Test Loss: 25965.45295394606\n",
      "Epoch: 55, Loss: 25966.847845732274\n",
      "Test Loss: 25828.505977557725\n",
      "Epoch: 56, Loss: 25876.651673274253\n",
      "Test Loss: 25757.439123457403\n",
      "Epoch: 57, Loss: 25786.297907782515\n",
      "Test Loss: 25702.29069839769\n",
      "Epoch: 58, Loss: 25695.64381496535\n",
      "Test Loss: 25582.652673417597\n",
      "Epoch: 59, Loss: 25607.737478553106\n",
      "Test Loss: 25542.45329294387\n",
      "Epoch: 60, Loss: 25511.678365288513\n",
      "Test Loss: 25334.18233728105\n",
      "Epoch: 61, Loss: 25435.69654101146\n",
      "Test Loss: 25265.32649221238\n",
      "Epoch: 62, Loss: 25355.31926930637\n",
      "Test Loss: 25296.7906641869\n",
      "Epoch: 63, Loss: 25269.86033802805\n",
      "Test Loss: 25114.623877264134\n",
      "Epoch: 64, Loss: 25198.88626898987\n",
      "Test Loss: 25191.855474970143\n",
      "Epoch: 65, Loss: 25136.922202950092\n",
      "Test Loss: 25003.921137913017\n",
      "Epoch: 66, Loss: 25083.259790611675\n",
      "Test Loss: 24914.052205662818\n",
      "Epoch: 67, Loss: 25028.589825009996\n",
      "Test Loss: 24899.634473278264\n",
      "Epoch: 68, Loss: 24980.741733575425\n",
      "Test Loss: 24952.150717182525\n",
      "Epoch: 69, Loss: 24937.84509511594\n",
      "Test Loss: 24901.104532618432\n",
      "Epoch: 70, Loss: 24899.97225021655\n",
      "Test Loss: 24708.497813619626\n",
      "Epoch: 71, Loss: 24868.08353877932\n",
      "Test Loss: 24774.574700811107\n",
      "Epoch: 72, Loss: 24829.921966617803\n",
      "Test Loss: 24703.85724771099\n",
      "Epoch: 73, Loss: 24787.80513830124\n",
      "Test Loss: 24750.971306478903\n",
      "Epoch: 74, Loss: 24770.391296516857\n",
      "Test Loss: 24801.777132265128\n",
      "Epoch: 75, Loss: 24729.73105177239\n",
      "Test Loss: 24675.782755274682\n",
      "Epoch: 76, Loss: 24698.837783390525\n",
      "Test Loss: 24536.57896471935\n",
      "Epoch: 77, Loss: 24680.443157399386\n",
      "Test Loss: 24700.483721884953\n",
      "Epoch: 78, Loss: 24649.62366113073\n",
      "Test Loss: 24545.509998880374\n",
      "Epoch: 79, Loss: 24625.377068688365\n",
      "Test Loss: 24624.2478385002\n",
      "Epoch: 80, Loss: 24599.04960687633\n",
      "Test Loss: 24527.15746914809\n",
      "Epoch: 81, Loss: 24577.99671529351\n",
      "Test Loss: 24512.656542346736\n",
      "Epoch: 82, Loss: 24545.212723006065\n",
      "Test Loss: 24466.17149868133\n",
      "Epoch: 83, Loss: 24541.661172374734\n",
      "Test Loss: 24570.816222755773\n",
      "Epoch: 84, Loss: 24517.87208697028\n",
      "Test Loss: 24518.116447302946\n",
      "Epoch: 85, Loss: 24492.950966776054\n",
      "Test Loss: 24374.977231165405\n",
      "Epoch: 86, Loss: 24481.274958563765\n",
      "Test Loss: 24426.49424947751\n",
      "Epoch: 87, Loss: 24457.91455806903\n",
      "Test Loss: 24409.685120795184\n",
      "Epoch: 88, Loss: 24429.28889175773\n",
      "Test Loss: 24377.071649830814\n",
      "Epoch: 89, Loss: 24418.41475171575\n",
      "Test Loss: 24477.37791102707\n",
      "Epoch: 90, Loss: 24400.620096365274\n",
      "Test Loss: 24385.45789895999\n",
      "Epoch: 91, Loss: 24386.86898654051\n",
      "Test Loss: 24351.38483715665\n",
      "Epoch: 92, Loss: 24370.352364155784\n",
      "Test Loss: 24323.354131419186\n",
      "Epoch: 93, Loss: 24353.35373842284\n",
      "Test Loss: 24216.712843973924\n",
      "Epoch: 94, Loss: 24335.921149345348\n",
      "Test Loss: 24329.083066903862\n",
      "Epoch: 95, Loss: 24323.36885327825\n",
      "Test Loss: 24387.080725019903\n",
      "Epoch: 96, Loss: 24305.115037604945\n",
      "Test Loss: 24151.369162395502\n",
      "Epoch: 97, Loss: 24301.911156758062\n",
      "Test Loss: 24201.792107260153\n",
      "Epoch: 98, Loss: 24279.97118411847\n",
      "Test Loss: 24191.37124614351\n",
      "Epoch: 99, Loss: 24268.39657911614\n",
      "Test Loss: 24336.159639978105\n"
     ]
    }
   ],
   "source": [
    "# Training setup\n",
    "model = VAE(in_channels=3)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss(reduction=\"sum\")\n",
    "\n",
    "# Training the autoencoder\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, _ in train_loader:\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        rec, mu, logvar = model(images)\n",
    "        bce_loss = criterion(rec, images)\n",
    "        loss = VAELoss(bce_loss, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch: {epoch}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "    # Test on test data\n",
    "    model.eval()\n",
    "    test_loss_sum = 0\n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:\n",
    "            images = images.to(device)\n",
    "            rec, mu, logvar = model(images)\n",
    "            bce_loss = criterion(rec, images)\n",
    "            loss = VAELoss(bce_loss, mu, logvar)\n",
    "            test_loss_sum += loss.item()\n",
    "        \n",
    "        test_loss = test_loss_sum / len(test_loader)\n",
    "        print(f\"Test Loss: {test_loss}\")\n",
    "        if (len(val_losses) > 5) and all(test_loss >= x for x in val_losses[-8:]):\n",
    "            print(\"Early Stopping...\")\n",
    "            break\n",
    "        val_losses.append(test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the VAE model\n",
    "torch.save(model.state_dict(), \"trained_models/vae_rgb.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Flatten(start_dim=1, end_dim=-1)\n",
       "    (9): Linear(in_features=256, out_features=128, bias=True)\n",
       "  )\n",
       "  (fc_mu): Linear(in_features=128, out_features=16, bias=True)\n",
       "  (fc_log_var): Linear(in_features=128, out_features=16, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Unflatten(dim=1, unflattened_size=(64, 2, 2))\n",
       "    (5): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (8): ReLU()\n",
       "    (9): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (10): ReLU()\n",
       "    (11): ConvTranspose2d(8, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (12): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28, 28])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    im, tgt = iter(test_loader).next()\n",
    "    im = im.to(device)\n",
    "    pred, _, _ = model(im)\n",
    "\n",
    "pred = pred[5]\n",
    "\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5083f9b9a0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred.cpu().numpy().squeeze().transpose(1, 2, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Mar 13 2023, 10:26:41) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
