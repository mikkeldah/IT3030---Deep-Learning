{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stacked_mnist import StackedMNISTData, DataMode\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the provided mnist dataset class\n",
    "gen = StackedMNISTData(mode=DataMode.MONO_BINARY_COMPLETE, default_batch_size=9)\n",
    "\n",
    "train_data = gen.get_full_data_set(training=True)\n",
    "test_data = gen.get_full_data_set(training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape, test_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000,)\n",
      "(10000, 28, 28, 1) (10000,)\n",
      "(28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x200a934ec10>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, y_train = train_data\n",
    "x_test, y_test = test_data\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "# Convert y_train and y_test into one-hot vectors\n",
    "y_train = to_one_hot(y_train)\n",
    "y_test = to_one_hot(y_test)\n",
    "\n",
    "img = x_train[np.random.randint(0, x_train.shape[0])]\n",
    "print(img.shape)\n",
    "\n",
    "plt.figure(figsize=(6, 4), dpi=150)\n",
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pytorch Image Classifier Model\n",
    "\n",
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self, image_depth=1):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(image_depth, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7 * 7 * 32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pytorch dataloaders from x_train and y_train\n",
    "x_train = torch.from_numpy(x_train.astype(np.float32)).permute(0, 3, 1, 2)\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create pytorch dataloaders from x_test and y_test\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32)).permute(0, 3, 1, 2)\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 408.9386843123939\n",
      "Epoch 1 loss: 124.04664756933926\n",
      "Epoch 2 loss: 87.49189082885277\n",
      "Epoch 3 loss: 62.51715957986016\n",
      "Epoch 4 loss: 50.096826777094975\n",
      "Epoch 5 loss: 36.621041059519484\n",
      "Epoch 6 loss: 30.83946824701343\n",
      "Epoch 7 loss: 22.32738084204493\n",
      "Epoch 8 loss: 18.863923184569103\n",
      "Epoch 9 loss: 16.452881228024125\n",
      "Epoch 10 loss: 12.9782811803056\n",
      "Epoch 11 loss: 11.980791888657109\n",
      "Epoch 12 loss: 9.072848177981257\n",
      "Epoch 13 loss: 8.75932927937091\n",
      "Epoch 14 loss: 8.11296191296855\n",
      "Epoch 15 loss: 7.707642289688025\n",
      "Epoch 16 loss: 6.7924239597355704\n",
      "Epoch 17 loss: 6.280734847431663\n",
      "Epoch 18 loss: 5.790490434832652\n",
      "Epoch 19 loss: 5.2836151796693045\n"
     ]
    }
   ],
   "source": [
    "# Training setup\n",
    "model = MNISTClassifier(image_depth=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images.squeeze(0)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch} loss: {total_loss}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 18.827587355025393\n",
      "Test accuracy: 98.91%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct_preds = 0\n",
    "    test_loss = 0\n",
    "    for x, y in test_loader:\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        pred = pred.argmax(dim=1, keepdim=True)\n",
    "        truth = y.argmax(dim=1, keepdim=True)\n",
    "        correct_preds += pred.eq(truth.view_as(pred)).sum().item()\n",
    "        \n",
    "\n",
    "    test_accuracy = correct_preds / len(test_loader.dataset)\n",
    "\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test accuracy: {100*test_accuracy}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
