{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stacked_mnist import StackedMNISTData, DataMode\n",
    "from models.auto_encoder import AutoEncoder\n",
    "from models.mnist_classifier import MNISTClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the provided mnist dataset class\n",
    "gen = StackedMNISTData(mode=DataMode.MONO_BINARY_COMPLETE, default_batch_size=9)\n",
    "\n",
    "train_data = gen.get_full_data_set(training=True)\n",
    "test_data = gen.get_full_data_set(training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape, test_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000,)\n",
      "(10000, 28, 28, 1) (10000,)\n",
      "(28, 28, 1)\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2405e2879d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAIFCAYAAAC+iaXHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAABcSAAAXEgFnn9JSAAAa+ElEQVR4nO3dfYwtd33f8c+3WLbxA8GxrlSXR2EFqC0RYqsYO0ppXUAoBMUQpxWJkEwpQiqoRsSRIgUjB6MKpIQYKQ0RCZgoUfNHwYEgHoOoG+qYBDDYiXHBJCHExIjHm+DrBxzy6x9n1l4uZ/d77+7Znb27r5d0NHtmzpz727mzd993zpk5NcYIAMBm/sXcAwAA9j7BAAC0BAMA0BIMAEBLMAAALcEAALQEAwDQEgwAQEswAAAtwQAAtAQDANASDABA66S5B7CTquqrSU5L8ndzjwUAZva4JPeOMf7lVlau/fxplVX1j0nOnHscALBHfGeM8aitrDj7SxJV9ciqen1VfaGq7q+qv6+qd1TVY1bw9I4sAMDDtvx7cdZgqKpTk3wsydVJzkjy3iy+mZcm+UxVPWnG4QEAk7mPMLw2yTOT3JzkyWOM/zTGuCjJLyQ5lOQdcw4OAFiYLRiq6uQkr5ruvnKMcc/asjHGm5PcluRZVXXhHOMDAB425xGGH0/yQ0n+aozxmSXL3zVNX7B7QwIAlpkzGH50mt6ywfK1+U/bhbEAAJuYMxgeP03v2mD52vwn7MJYAIBNzHnhpjOm6b0bLD8yTdvrKFTV7RssOvd4BwUA/KC5z5IAAE4Acx5hWDsr4rQNlp8+Tb/TPdEY4/xl86cjD+cd/9AAgPXmPMLw5Wn62A2Wr83/210YCwCwiTmD4dZpesEGy9fm37YLYwEANjFnMNyU5B+SnFtVT1+y/PJp+r5dGxEAsNRswTDG+G6S35ju/o+qWnvPQqrqNVlcf+H/jDE+Pcf4AICHzfmmxyR5Q5JnJ7kkyZ1V9fEsrrtwUZKvJ/nPM44NAJjMelrlGOP+JP8+ybVZXI/hsiyC4Z1JLhhj/PVsgwMAHlJjjLnHsGOcVgkA3+dzG12KoOPCTQBASzAAAC3BAAC0BAMA0BIMAEBLMAAALcEAALQEAwDQEgwAQEswAAAtwQAAtAQDANASDABASzAAAC3BAAC0BAMA0BIMAEBLMAAALcEAALQEAwDQEgwAQEswAAAtwQAAtAQDANASDABASzAAAC3BAAC0BAMA0BIMAEBLMAAALcEAALROmnsAwN43xtjW+lW1opEAc3GEAQBoCQYAoCUYAICWYAAAWoIBAGgJBgCgJRgAgJZgAABaggEAaAkGAKAlGACAlmAAAFqCAQBoCQYAoCUYAIDWSXMPANj7qmpb648xZh8DsD2OMAAALcEAALQEAwDQEgwAQEswAAAtwQAAtAQDANASDABASzAAAC3BAAC0BAMA0BIMAEBLMAAALcEAALQEAwDQOmnuAQB73xhj7iFsewxVtaKRwME06xGGqrqxqsYmt+fNOT4AYGGvHGF4d5J7lsz/ym4PBAD4QXslGK4aY3xp7kEAAMt50yMA0BIMAEBrr7wk8bKqOjvJPyf5QpL3jDG+PPOYAIBJzXm6VFXdmORZSxY9mOTaMca1x/g8t2+w6Nwkp2xtdMCavXBa5XY5rRKSJJ8bY5y/lRXnfkniT5K8JItf7KcleUqSX07yT0leX1VXzjg2AGAy6xGGjVTVc5N8OMnhJP9qjHHfFp/n9iTnrXBocCDtxX8njpcjDJDkBD7CsNQY4yNJPpXk0Ukumnc0AMCeDIbJndP0nFlHAQDs6WA4a5oemXUUAMDeDIaqOpTkJ6a7t8w5FgBgxmCoqkuq6rKqesRR85+Y5A+TnJ7kj8YYd80xPgDgYXNeuOnJSa5P8tWquiWLMyKekOTCJKcmuT3Jy2cbHQDwkDmD4c+SvDWLsyD+TRbvWTiS5LNJ/leSt271dEoAYLVmC4Yxxh1J/utcfz4AcOz25JseAYC9RTAAAC3BAAC0BAMA0BIMAEBLMAAALcEAALQEAwDQEgwAQEswAAAtwQAAtAQDANASDABASzAAAC3BAAC0BAMA0BIMAEBLMAAALcEAALQEAwDQEgwAQEswAAAtwQAAtAQDANASDABASzAAAC3BAAC0BAMA0BIMAEBLMAAALcEAALQEAwDQEgwAQEswAAAtwQAAtAQDANASDABASzAAAC3BAAC0BAMA0BIMAEBLMAAALcEAALQEAwDQEgwAQEswAAAtwQAAtAQDANASDABASzAAAC3BAAC0BAMA0BIMAEBLMAAALcEAALQEAwDQEgwAQEswAAAtwQAAtAQDANASDABASzAAAC3BAAC0Tpp7AMDOG2PMPQTgBLeSIwxVdWFV/VJV3VBVd1XVqKr2X6iquqKq/ryq7qmqb1XVB6rqklWMCQBYnVUdYbg6yU8fzwpVdV2SK5Pcl+QjSU5N8pwkz62qy8cY71nR2ACAbVpVMNyc5LYkn5xuX0pyykYPrqpnZxEL30xy8Rjjzmn+xUluTHJ9Vd04xji8ovEBANuwkmAYY7xp/f2q6lZ5zTR9w1osTM9zc1X9VpL/luRlSX5tFeMDALZn18+SqKpHJrl0uvuuJQ9Zm/eC3RkRANCZ47TKp2TxcsXXxxh3LVl+yzR92u4NCQDYzBynVT5+mi6LhYwxjlTV4SRnVdWZY4zvdE9YVbdvsOjcrQ0RAFhvjiMMZ0zTezd5zJFpeuYOjwUAOAb74sJNY4zzl82fjjyct8vDAYB9Z44jDPdM09M2eczp07R9OQIA2HlzBMOXp+ljly2sqtOTPDrJt4/l/QsAwM6bIxg+n+SBJIeq6jFLll8wTW/bvSEBAJvZ9WAYY9yX5GPT3Z9d8pDLp+n7dmdEAEBnro+3fvM0fW1V/cjazOnS0K9IcjjJ22cYFwCwxErOkqiq52fxAVRrTp7mf2LdvGvHGO9PkjHGR6vqLVl8nsRnq+qPp3Wek6SSvNTnSADA3rGq0yoPJbloyfyLjnrMQ8YYr66qzyZ5VRah8N0kH80iLP50ReMCAFagxhhzj2HHuA4DLOznn/NjdQwfigcHwec2unZRZ673MAAAJxDBAAC0BAMA0BIMAEBLMAAALcEAALQEAwDQEgwAQEswAAAtwQAAtAQDANASDABASzAAAC3BAAC0BAMA0BIMAEBLMAAALcEAALQEAwDQEgwAQEswAAAtwQAAtAQDANASDABASzAAAC3BAAC0BAMA0BIMAEBLMAAALcEAALQEAwDQEgwAQEswAAAtwQAAtAQDANASDABASzAAAC3BAAC0BAMA0BIMAEBLMAAALcEAALQEAwDQEgwAQEswAAAtwQAAtAQDANASDABASzAAAC3BAAC0BAMA0BIMAEBLMAAALcEAALQEAwDQEgwAQEswAAAtwQAAtAQDANASDABASzAAAC3BAAC0BAMA0BIMAEBrJcFQVRdW1S9V1Q1VdVdVjaoamzz+mrXHbHB74yrGBQCsxkkrep6rk/z0Fta7KckXl8z/9PaGAwCs0qqC4eYktyX55HT7UpJTjmG93xljvHNFYwAAdshKgmGM8ab196tqFU8LAOwR3vQIALRW9ZLEVl1aVU9PcmqSu5J8cIzh/QsAsMfMHQwvOer+tVX17iRXjDHuOdYnqarbN1h07pZHBgA8ZK6XJL6Y5Kok5yc5I8njkvx8kq8k+ZkkvzfTuACAJWqMDS+XsPUnrbo/ySljjON692NVnZPkL5KcneTiMcYntjmO25Oct53ngP1gJ37OTzTejA1Jks+NMc7fyop76k2PY4y7k1w/3X3enGMBAB62p4Jhcuc0PWfWUQAAD9mLwXDWND0y6ygAgIfsqWCoxYuML5zu3jLnWACAh+16MFTVoap6ZVWdedT8M5K8NclFSb6a5IbdHhsAsNxKrsNQVc/P4gOo1pw8zV9/lsO1Y4z3Jzk9yW8keWNVfTLJ3UkOJbkgi7MjDie5fIxx7yrGBgBs36ou3HQoiyMDR7voqMckyTeTvCnJM5M8OcklSb6X5G+SvDPJr48xvrKicQEAK7Aj12HYK1yHARb288/5sXIdBkiyX67DAADsTYIBAGgJBgCgJRgAgJZgAABaggEAaAkGAKAlGACAlmAAAFqCAQBoCQYAoCUYAICWYAAAWoIBAGgJBgCgJRgAgJZgAABaggEAaAkGAKAlGACAlmAAAFqCAQBoCQYAoCUYAICWYAAAWoIBAGgJBgCgJRgAgJZgAABaggEAaAkGAKAlGACAlmAAAFqCAQBoCQYAoCUYAICWYAAAWoIBAGgJBgCgJRgAgJZgAABaggEAaAkGAKAlGACAlmAAAFqCAQBoCQYAoCUYAICWYAAAWoIBAGgJBgCgJRgAgJZgAABaggEAaAkGAKAlGACAlmAAAFqCAQBoCQYAoCUYAICWYAAAWoIBAGgJBgCgJRgAgNZKgqGqTquqy6rq7VX1+aq6v6qOVNWtVfW6qjpjk3WvqKo/r6p7qupbVfWBqrpkFeMCAFajxhjbf5Kq/5Lkt6e7dyT5yySPSnJJkjOT/L8kzxpjfO2o9a5LcmWS+5J8JMmpSf5Dkkpy+RjjPdsc1+1JztvOc8B+sIqf8xNdVc09BNgLPjfGOH8rK67qJYkHk7wtyXljjPPGGP9xjPG8JE9J8pkkT01y3foVqurZWcTCN5P86Bjjsmmdf5vke0mur6pHr2h8AMA2rCQYxhi/O8Z4xRjjjqPm353kldPdF1XVyesWv2aavmGMcee6dW5O8ltJHp3kZasYHwCwPbvxpsdbp+kpSc5Okqp6ZJJLp/nvWrLO2rwX7OzQAIBjsRvB8KRp+mCSb01fPyWLgPj6GOOuJevcMk2ftsNjAwCOwUm78GdcOU0/NMZ4YPr68dN0WSxkjHGkqg4nOauqzhxjfGezP2B6c+My5x7vYAGAH7SjRxiq6iezeB/Cg0muXrdo7TTLezdZ/cg0PXMHhgYAHIcdO8JQVU9N8vtZnCL5i2OMW5tVtmyjU0ScVgkAq7EjRxiq6jFJPpTkrCRvHmO85aiH3DNNT9vkaU6fppu+HAEA7LyVB0NV/XAWF2F6QpLrk1y15GFfnqaP3eA5Ts/itMpvd+9fAAB23kqDYboE9AezeBnghiQvH8svMff5JA8kOTQdjTjaBdP0tlWODwDYmpUFQ1WdkuS9SZ6R5MNJXjzG+N6yx44x7kvysenuzy55yOXT9H2rGh8AsHWr+vCpRyT5gywuxvTxJC8aY3y3We3N0/S1VfUj657r4iSvSHI4ydtXMT4AYHtWdZbEq5K8cPr6G0l+c4MPerlqjPGNJBljfLSq3pLFdRo+W1V/nOTkJM/J4syKl44xDq9ofADANqwqGM5a9/ULN3xUck0WQZEkGWO8uqo+m0VwPCfJd5N8NMm1Y4w/XdHYAIBtWsnHW+9VrsMAC/v55/xY+XhrSLIHPt4aANjHBAMA0BIMAEBLMAAALcEAALQEAwDQEgwAQEswAAAtwQAAtAQDANASDABASzAAAC3BAAC0BAMA0Dpp7gEAO2+7H+28Fz4e28dTw7wcYQAAWoIBAGgJBgCgJRgAgJZgAABaggEAaAkGAKAlGACAlmAAAFqCAQBoCQYAoCUYAICWYAAAWoIBAGgJBgCgddLcAwD2vqqaewjAzBxhAABaggEAaAkGAKAlGACAlmAAAFqCAQBoCQYAoCUYAICWYAAAWoIBAGgJBgCgJRgAgJZgAABaggEAaAkGAKAlGACAlmAAAFqCAQBoCQYAoCUYAICWYAAAWoIBAGgJBgCgJRgAgJZgAABaggEAaAkGAKAlGACAlmAAAFqCAQBoCQYAoCUYAICWYAAAWisJhqo6raouq6q3V9Xnq+r+qjpSVbdW1euq6owl61xTVWOT2xtXMTYAYPtOWtHz/FyS356+viPJHyV5VJJLkvxKkhdX1bPGGF9bsu5NSb64ZP6nVzQ2AGCbVhUMDyZ5W5Lrxhh3rM2sqnOSvD/JjyW5LouwONrvjDHeuaJxAAA7YCUvSYwxfneM8Yr1sTDNvzvJK6e7L6qqk1fx5wEAu2s33vR46zQ9JcnZu/DnAQArtqqXJDbzpGn6YJJvLVl+aVU9PcmpSe5K8sExhvcvAMAeshvBcOU0/dAY44Ely19y1P1rq+rdSa4YY9xzLH9AVd2+waJzj3GMAMAmdvQliar6ySQvy+LowtVHLf5ikquSnJ/kjCSPS/LzSb6S5GeS/N5Ojg0AOHY1xtiZJ656apI/TXJWklePMd5yjOudk+Qvsni/w8VjjE9sYwy3Jzlvq+sDwD7zuTHG+VtZcUeOMFTVY5J8KItYePOxxkLy0JkV1093n7cDwwMAjtPKg6GqfjjJR5I8IYtf/Fdt4WnunKbnrGpcAMDWrTQYpktAfzCLlwFuSPLysbXXPM6apkdWNTYAYOtWFgxVdUqS9yZ5RpIPJ3nxGON7W3ieSvLC6e4tqxofALB1q/rwqUck+YMklyb5eJIXjTG+u8njD1XVK6vqzKPmn5HkrUkuSvLVLI5SAAAzW9V1GF6Vh48KfCPJby4OFPyAq8YY30hyepLfSPLGqvpkkruTHEpyQRZnRxxOcvkY494VjQ8A2IZVBcNZ675+4YaPSq7JIii+meRNSZ6Z5MlZfKrl95L8TZJ3Jvn1McZXVjQ2AGCbduw6DHuB6zAAwPfZW9dhAAD2F8EAALQEAwDQEgwAQEswAAAtwQAAtAQDANASDABASzAAAC3BAAC0BAMA0BIMAEBLMAAALcEAALQEAwDQEgwAQEswAAAtwQAAtAQDANASDABASzAAAC3BAAC0BAMA0BIMAEBLMAAALcEAALQEAwDQEgwAQEswAACt/R4Mj5t7AACwh2z59+JJqxzFHnTvNP27DZafO03/ahfGsl/ZhttnG26fbbh9tuH27fVt+Lg8/HvxuNUYY4VjObFU1e1JMsY4f+6xnKhsw+2zDbfPNtw+23D79vs23O8vSQAAKyAYAICWYAAAWoIBAGgJBgCgdaDPkgAAjo0jDABASzAAAC3BAAC0BAMA0BIMAEBLMAAALcEAALQEAwDQOpDBUFWPrKrXV9UXqur+qvr7qnpHVT1m7rGdCKrqxqoam9yeN/cY94KqurCqfqmqbqiqu9a2zzGsd0VV/XlV3VNV36qqD1TVJbsx5r3meLdhVV3T7Jtv3M3xz62qTquqy6rq7VX1+enfuyNVdWtVva6qzthkXfthtrYN9+t+eNLcA9htVXVqko8leWaSu5O8N8kTk7w0yU9V1TPHGH893whPKO9Ocs+S+V/Z7YHsUVcn+enjWaGqrktyZZL7knwkyalJnpPkuVV1+RjjPSse41533NtwclOSLy6Z/+ntDeeE83NJfnv6+o4kf5TkUUkuSfIrSV5cVc8aY3xt/Ur2w++zpW042Vf74YELhiSvzSIWbk7y3DHGPUlSVa9J8mtJ3pHk3802uhPLVWOML809iD3s5iS3JfnkdPtSklM2enBVPTuLf6S/meTiMcad0/yLk9yY5PqqunGMcXhHR723HNc2XOd3xhjv3LlhnTAeTPK2JNeNMe5Ym1lV5yR5f5IfS3JdFr8U15bZD7/fcW/DdfbXfjjGODC3JCcnOZxkJPmxJctvnZZdOPdY9/Iti380RpInzj2WE+mW5P7Fj9yGyz8wbddXL1n2lmnZL8z9fezxbXjNtJ2umHuse/2W5OJpW92f5OR18+2H29+G+3I/PGjvYfjxJD+U5K/GGJ9Zsvxd0/QFuzckWLyvJsml0913LXmIfZNVu3WanpLk7MR+uAU/sA33s4P2ksSPTtNbNli+Nv9puzCW/eBlVXV2kn9O8oUk7xljfHnmMZ2onpLFPzpfH2PctWS5ffP4XFpVT8/itfe7knxwjHFCvm68g540TR9M8q3pa/vh8Vm2DdfbV/vhQQuGx0/TZT8I6+c/YRfGsh+89qj7v1pV144xrp1lNCe2TffNMcaRqjqc5KyqOnOM8Z1dG9mJ6SVH3b+2qt6dxSHiZW/UPYiunKYfGmM8MH1tPzw+y7bhevtqPzxoL0msnf5y7wbLj0zTM3dhLCeyP8niB+HcJKdl8b+SX07yT0leX1VXbrIuy3X7ZmL/PBZfTHJVkvOz2KaPS/LzWZy58zNJfm++oe0dVfWTSV6Wxf+Mr163yH54jDbZhsk+3Q8P2hEGVmCM8bqjZn0hyX+vqk8l+XCSa6rqbWOM+3Z/dBxkY4zfP2rWkST/s6r+d5K/SHLZdOr0J3Z/dHtDVT01ye8nqSS/OMa4tVmFo3TbcL/uhwftCMPaIaDTNlh++jQ96IfZtmSM8ZEkn0ry6CQXzTuaE063byb2zy0bY9yd5Prp7oG9sNh0cboPJTkryZvHGG856iH2w8YxbMMNnej74UELhrU35D12g+Vr8/92F8ayX905Tc+ZdRQnnk33zao6PYsQ+7bXjbfsQO+bVfXDWVyE6QlZ/NK6asnD7IebOMZt2Dlh98ODFgxrh40u2GD52vzbdmEs+9VZ0/TIpo/iaJ9P8kCSQxtcoty+uX0Hdt+cLl/8wSTnJbkhycvHdMGAo9gPN3Ac27Bzwu6HBy0YbkryD0nOnU51Odrl0/R9uzaifaSqDiX5ienuRqeussT0fo+PTXd/dslD7JvbUFWV5IXT3QO1b1bVKVlcAv8ZWbzH6MVjjO8te6z9cLnj2YbN85zY++HcV47a7VuSN2RxBa6bkpy+bv5rpvk3zj3GvXzL4vrplyV5xFHzn5jk/07b8L1zj3Mv3tJfpfDZ0/b7RpIfWTf/4mndbyd59Nzfx17dhkkOJXllkjOPmn9Gkt+atu3dSU6b+/vYxe31iCz+NzyyOLup/d7th9vbhvt5P6zpGzkwpg+fujGLN+XdneTjWbwedVGSryfx4VObqKorsnjt7qtZFPLhLLbfhVlcnOT2JJeO5R/EcqBU1fPz/adbPSOLd1X/2bp5144x3r9uneuyOLf73iR/nMXlzJ8zrXfQPvTnuLZhVT0xyd9k8ca9T2bx830oi8PoZ2exr/7UGOOmnR/53jCd4nzddPcPk/zjBg+9aozxjXXrXRf7YZLj34b7ej+cu1hmKsZHJnl9FufKPpDFX+j1SR4799j2+i3Jv07ym1l82trXsjgH+XAWHxL0miSPnHuMe+WW5Ios/jex2e2KDdb7VBavcX47i9dNL5n7+9nr2zCL6wK8MYv/ENyVxf+GjyT5yyS/muQxc38/M2y/a45h+y39XBj74da24X7eDw/cEQYA4PgdtDc9AgBbIBgAgJZgAABaggEAaAkGAKAlGACAlmAAAFqCAQBoCQYAoCUYAICWYAAAWoIBAGgJBgCgJRgAgJZgAABaggEAaAkGAKD1/wGPQBiEL3Pl6AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, y_train = train_data\n",
    "x_test, y_test = test_data\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "# Convert y_train and y_test into one-hot vectors\n",
    "y_train = to_one_hot(y_train)\n",
    "y_test = to_one_hot(y_test)\n",
    "\n",
    "rand = np.random.randint(0, x_train.shape[0])\n",
    "img = x_train[rand]\n",
    "label = y_train[rand]\n",
    "print(img.shape)\n",
    "\n",
    "print(label)\n",
    "print(label.argmax())\n",
    "plt.figure(figsize=(6, 4), dpi=150)\n",
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pytorch dataloaders from x_train and y_train\n",
    "x_train = torch.from_numpy(x_train.astype(np.float32)).permute(0, 3, 1, 2)\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create pytorch dataloaders from x_test and y_test\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32)).permute(0, 3, 1, 2)\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.17258749486605326\n",
      "Test Loss: 0.11047243583983125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18840/2214651268.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikke\\Courses\\Spring 2023\\Dyp Læring\\IT3030---Deep-Learning\\Project 3 - Deep Generative Models\\models\\auto_encoder.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, output_size)\u001b[0m\n\u001b[0;32m    954\u001b[0m             num_spatial_dims, self.dilation)  # type: ignore[arg-type]\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m         return F.conv_transpose2d(\n\u001b[0m\u001b[0;32m    957\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m             output_padding, self.groups, self.dilation)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training setup\n",
    "model = AutoEncoder(in_channels=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Training the autoencoder\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, _ in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch: {epoch}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "    # Test on test data\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:\n",
    "            output = model(images)\n",
    "            loss = criterion(output, images)\n",
    "            test_loss += loss.item()\n",
    "        print(f\"Test Loss: {test_loss / len(test_loader)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the AutoEncoder model\n",
    "torch.save(model.state_dict(), \"trained_models/auto_encoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0003284663547287238\n"
     ]
    }
   ],
   "source": [
    "# Test the auto encoder\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, _ in test_loader:\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, x)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "print(f\"Test Loss: {test_loss / len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_classifier = MNISTClassifier(1)\n",
    "mnist_classifier.load_state_dict(torch.load('trained_models/mnist_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.9%\n"
     ]
    }
   ],
   "source": [
    "correct_preds = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        ae_output = model(x)\n",
    "\n",
    "        ae_output_class = mnist_classifier(ae_output)\n",
    "        ae_output_class = ae_output_class.argmax(dim=1, keepdim=True)\n",
    "        truth = y.argmax(dim=1, keepdim=True)\n",
    "\n",
    "        correct_preds += ae_output_class.eq(truth.view_as(ae_output_class)).sum().item()\n",
    "\n",
    "    accuracy = correct_preds / len(test_loader.dataset)\n",
    "\n",
    "print(f\"Accuracy: {100*accuracy}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
